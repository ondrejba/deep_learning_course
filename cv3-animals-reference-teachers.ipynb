{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MI-MVI tutorial 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">In the previous two tutorial, we classified images with Fully-connected Neural Networks. While these networks can achieve satisfying results on simple datasets, their ability to model complex images is significantly limited.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![animals](images/animals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">We created a small dataset of **animals**. From top to bottom: cat, deer, dog and horse. The task is to train a Neural Network to distinguish between the four classes.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">**Import** packages we will need.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">**Load** pictures of cars and airplanes. The pictures are already prepared for you as [numpy arrays](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/animals/dataset.pickle\"\n",
    "    \n",
    "with open(dataset_path, \"rb\") as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">We will work with 8000 training, 1000 validation and 1000 testing pictures. All pictures contain color and span 32 x 32 pixels.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train airplanes:\", dataset[\"train_data\"].shape)\n",
    "print(\"valid airplanes:\", dataset[\"valid_data\"].shape)\n",
    "print(\"test airplanes:\", dataset[\"test_data\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">**Normalize** images so that they have zero mean and unit variance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(dataset[\"train_data\"], axis=0)\n",
    "std = np.std(dataset[\"train_data\"], axis=0)\n",
    "\n",
    "dataset[\"train_data\"] = (dataset[\"train_data\"] - mean) / std\n",
    "dataset[\"valid_data\"] = (dataset[\"valid_data\"] - mean) / std\n",
    "dataset[\"test_data\"] = (dataset[\"test_data\"] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">Notice that we compute means and standard deviations over the training set. As expected, the training set has zero mean and unit variance after normalization. However, the means and variances of the validation and testing set sligtly deviate. Why do we use means and standard deviations computed over the training set to normalize the validation and testing sets? *Hint: generalization*.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training mean:\", np.round(np.mean(dataset[\"train_data\"]), 5), \", variance:\", \n",
    "                        np.round(np.var(dataset[\"train_data\"]), 5))\n",
    "print(\"validation mean:\", np.round(np.mean(dataset[\"valid_data\"]), 5), \", variance:\", \n",
    "                          np.round(np.var(dataset[\"valid_data\"]), 5))\n",
    "print(\"testing mean:\", np.round(np.mean(dataset[\"test_data\"]), 5), \", variance:\", \n",
    "                       np.round(np.var(dataset[\"test_data\"]), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">**Shuffle** the pictures.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_labels = unison_shuffle(dataset[\"train_data\"], dataset[\"train_labels\"])\n",
    "valid_dataset, valid_labels = unison_shuffle(dataset[\"valid_data\"], dataset[\"valid_labels\"])\n",
    "test_dataset, test_labels = unison_shuffle(dataset[\"valid_data\"], dataset[\"test_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Convolutional Neural Networks ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">Fully-connected neural network are not appropriate for modelling images becuase they aren't invariant to translations and have too many weights. For these reasons, a different type of neural network was developed. Convolutional Neural Networks (ConvNets) use filters and max-pooling layers to keep the number of weights low and to learn to recognize object regardless of their position in the image. Moreover, they are easy to implement in Tensorflow</span>\n",
    "\n",
    "<span style=\"font-size:larger;\">Implement a simple ConvNet with convolutional, max-pooling and dense layers.</span>\n",
    "\n",
    "<span style=\"font-size:larger;\">Useful links:</span>\n",
    "* [lecture notes Stanford University **(recommended)**](http://cs231n.github.io/convolutional-networks/)\n",
    "* [Tensorflow tutorial](https://www.tensorflow.org/tutorials/layers)\n",
    "\n",
    "<span style=\"font-size:larger;\">See the reference notebook for a solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_turn_to_one_hot(labels, num_labels=4):\n",
    "  if len(labels.shape) == 1:\n",
    "    one_hot = np.zeros((labels.shape[0], num_labels))\n",
    "    one_hot[np.arange(len(labels)), labels] = 1\n",
    "    return one_hot\n",
    "  else:\n",
    "    return labels\n",
    "\n",
    "train_labels = maybe_turn_to_one_hot(train_labels)\n",
    "valid_labels = maybe_turn_to_one_hot(valid_labels)\n",
    "test_labels = maybe_turn_to_one_hot(test_labels)\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', valid_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TF remembers everything you defined, this will keep the computation graph clean\n",
    "tf.reset_default_graph()   \n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "# placeholders for data, we will fill these using the feed dictionary during training\n",
    "input_data = tf.placeholder(tf.float32, (None, train_dataset.shape[1], train_dataset.shape[2], 3))\n",
    "input_labels = tf.placeholder(tf.int32, (None, train_labels.shape[1]))\n",
    "\n",
    "# define convolutional and pooling layers\n",
    "conv1 = tf.layers.conv2d(input_data, 16, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, (2, 2), (2, 2))\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, 32, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, (2, 2), (2, 2))\n",
    "\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "# define fully-connected (or dense) layers\n",
    "dense1 = tf.layers.dense(flattened, 50)\n",
    "logits = tf.layers.dense(dense1, 4)\n",
    "\n",
    "# define loss and training operation\n",
    "batch_loss = tf.nn.softmax_cross_entropy_with_logits(labels=input_labels, logits=logits)\n",
    "loss = tf.reduce_mean(batch_loss)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# calcualte average accuracy over a batch of images\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(input_labels, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_steps = 1000\n",
    "mini_batch_size = 64\n",
    "log_frequency = 100\n",
    "\n",
    "# how many steps are in one epoch (epoch = one pass through the dataset)\n",
    "# e.g. number of training samples = 50, mini batch size = 10 => steps per epoch = 5\n",
    "steps_per_epoch = train_dataset.shape[0] // mini_batch_size\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "  # initialize all parameters of the neural network\n",
    "  session.run(tf.global_variables_initializer())\n",
    "\n",
    "  for step in range(num_steps):\n",
    "        \n",
    "    # step number relative to the current epoch (epoch = one pass through the dataset)\n",
    "    # e.g. number of training samples = 50, step = 60 => epoch step = 60 % 50 = 10\n",
    "    epoch_step = step % steps_per_epoch\n",
    "        \n",
    "    # start and end index for the current minibatch\n",
    "    # e.g. mini batch size = 64, start = 10, end = 74 => take all images from index 10 to 74\n",
    "    start = epoch_step * mini_batch_size\n",
    "    end = (epoch_step +  1) * mini_batch_size\n",
    "    \n",
    "    # if this is the first step in the current epoch, shuffle the training set\n",
    "    # we do this so that the model does not overfit on individual minibatches\n",
    "    if epoch_step == 0:\n",
    "        print(\"epoch\", step // steps_per_epoch)\n",
    "        train_dataset, train_labels = unison_shuffle(train_dataset, train_labels)\n",
    "    \n",
    "    # run one step of mini-batch gradient descent\n",
    "    batch_loss, batch_accuracy, _ = session.run([loss, accuracy, train_op], feed_dict={\n",
    "      input_data: train_dataset.take(range(start, end), axis=0, mode=\"wrap\"),\n",
    "      input_labels: train_labels.take(range(start, end), axis=0, mode=\"wrap\")\n",
    "    })\n",
    "    \n",
    "    # sometimes print the current loss\n",
    "    if step % log_frequency == 0:\n",
    "      print('step:', step, ', loss:', batch_loss, ', training accuracy:', batch_accuracy)\n",
    "    \n",
    "  print('Training finished after', num_steps, 'steps.')\n",
    "  \n",
    "  # evaluate the model on the validation set  \n",
    "  validation_accuracy = session.run(accuracy, feed_dict={\n",
    "    input_data: valid_dataset,\n",
    "    input_labels: valid_labels\n",
    "  })\n",
    "    \n",
    "  print('Validation accuracy', validation_accuracy, '.')\n",
    "\n",
    "# we do not save the model so the parameters are forgotten right after the training finishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Regularizing Convolutional Networks ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:larger;\">All neural networks are prone to overfitting if the training dataset is too small. Implement dropout for your ConvNet. See the reference notebook for a solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()   # TF remembers everything you defined, this will keep the computation graph clean\n",
    "\n",
    "learning_rate = 0.05\n",
    "dropout_prob = 0.5\n",
    "\n",
    "input_data = tf.placeholder(tf.float32, (None, train_dataset.shape[1], \n",
    "                                         train_dataset.shape[2], train_dataset.shape[3]))\n",
    "input_labels = tf.placeholder(tf.int32, (None, train_labels.shape[1]))\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "conv1 = tf.layers.conv2d(input_data, 16, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, (2, 2), (2, 2))\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, 32, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, (2, 2), (2, 2))\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "dense1 = tf.layers.dense(flattened, 100)\n",
    "dropout = tf.layers.dropout(dense1, rate=dropout_prob, training=is_training)\n",
    "\n",
    "logits = tf.layers.dense(dropout, 4)\n",
    "\n",
    "batch_loss = tf.nn.softmax_cross_entropy_with_logits(labels=input_labels, logits=logits)\n",
    "loss = tf.reduce_mean(batch_loss)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(input_labels, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_steps = 1000\n",
    "mini_batch_size = 64\n",
    "log_frequency = 100\n",
    "\n",
    "# how many steps are in one epoch (epoch = one pass through the dataset)\n",
    "# e.g. number of training samples = 50, mini batch size = 10 => steps per epoch = 5\n",
    "steps_per_epoch = train_dataset.shape[0] // mini_batch_size\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "  # initialize all parameters of the neural network\n",
    "  session.run(tf.global_variables_initializer())\n",
    "\n",
    "  for step in range(num_steps):\n",
    "        \n",
    "    # step number relative to the current epoch (epoch = one pass through the dataset)\n",
    "    # e.g. number of training samples = 50, step = 60 => epoch step = 60 % 50 = 10\n",
    "    epoch_step = step % steps_per_epoch\n",
    "        \n",
    "    # start and end index for the current minibatch\n",
    "    # e.g. mini batch size = 64, start = 10, end = 74 => take all images from index 10 to 74\n",
    "    start = epoch_step * mini_batch_size\n",
    "    end = (epoch_step +  1) * mini_batch_size\n",
    "    \n",
    "    # if this is the first step in the current epoch, shuffle the training set\n",
    "    # we do this so that the model does not overfit on individual minibatches\n",
    "    if epoch_step == 0:\n",
    "        print(\"epoch\", step // steps_per_epoch)\n",
    "        train_dataset, train_labels = unison_shuffle(train_dataset, train_labels)\n",
    "    \n",
    "    # run one step of mini-batch gradient descent\n",
    "    batch_loss, batch_accuracy, _ = session.run([loss, accuracy, train_op], feed_dict={\n",
    "      input_data: train_dataset.take(range(start, end), axis=0, mode=\"wrap\"),\n",
    "      input_labels: train_labels.take(range(start, end), axis=0, mode=\"wrap\"),\n",
    "      is_training: True\n",
    "    })\n",
    "    \n",
    "    # sometimes print the current loss\n",
    "    if step % log_frequency == 0:\n",
    "      print('step:', step, ', loss:', batch_loss, ', training accuracy:', batch_accuracy)\n",
    "    \n",
    "  print('Training finished after', num_steps, 'steps.')\n",
    "  \n",
    "  # evaluate the model on the validation set  \n",
    "  validation_accuracy = session.run(accuracy, feed_dict={\n",
    "    input_data: valid_dataset,\n",
    "    input_labels: valid_labels,\n",
    "    is_training: False\n",
    "  })\n",
    "    \n",
    "  print('Validation accuracy', validation_accuracy, '.')\n",
    "\n",
    "# we do not save the model so the parameters are forgotten right after the training finishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources   ##\n",
    "\n",
    "** Saving and restoring models in Tensorfow **\n",
    "* [tutorial](https://www.tensorflow.org/programmers_guide/saved_model)\n",
    "\n",
    "** Visualizing learning using Tensorboard **\n",
    "* [tutorial](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n",
    "\n",
    "** Convolutional Networks **\n",
    "* [lecture notes Stanford University **(recommended)**](http://cs231n.github.io/convolutional-networks/)\n",
    "* [lecture video from the University of Oxford](https://www.youtube.com/watch?v=bEUX_56Lojc)\n",
    "* [Tensorflow tutorial](https://www.tensorflow.org/tutorials/layers)\n",
    "\n",
    "** Dropout **\n",
    "* [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/dropout)\n",
    "* [paper](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n",
    "\n",
    "** Advanced data loading features in Tensorflow **\n",
    "* [tutorial](https://www.tensorflow.org/programmers_guide/datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out different dataset ##\n",
    "\n",
    "* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "* [CIFAR-10](https://www.kaggle.com/c/cifar-10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
