{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MI-MVI tutorial 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous two tutorial, we classified images with fully-connected neural networks. While these networks can achieve satisfactory results on simple image datasets, their ability to model complex natural images is significantly limited.\n",
    "\n",
    "Consider the following four pictures of cats from our dataset:\n",
    "\n",
    "![cats](images/cats.png)\n",
    "\n",
    "The cats occupy different parts of the images. This is problematic for a fully-connected neural network because it has an individual weight for each pixel of the image (more precisely 3 weights for the red, green and blue values). The set of weights that detects a cat in the center of the last image is independent from the weights that find the cat in the top-left corner of the 3rd image. Therefore, the fully-connected network needs to learn the same pattern several times for different locations.\n",
    "\n",
    "We would like our neural network to detect an object regardless of its location in the image. The property is called **location invariance**.\n",
    "\n",
    "**Convolutional Neural Networks** were developed specifically for image classification. They posses several desirable properties including location invariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![animals](images/animals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a small dataset of four **animals**: cats, deers, dogs and horses. The task in this tutorial is to distinguish between the four classes. We will tackle the classification problem with Convolutional Neural Networks.\n",
    "\n",
    "All pictures are 32 x 32 pixels in size and are encoded in the RGB format.\n",
    "\n",
    "The dataset is a subset of a larger dataset called [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). We encourage you to experiment with the whole dataset after you complete this tutorial. The *cv3-animals-prepare-data* notebook will help you prepare the dataset (although you will need to change some code to prepare all 10 classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download** the dataset from this [link](https://drive.google.com/file/d/1_jWafqplCoV4OAC0hoQv5Ibxe69N7UjN/view?usp=sharing) and place it in the **data/animals** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import** packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load** pictures of the animals. The pictures are already prepared for you in a Python [pickle](https://docs.python.org/3/library/pickle.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/animals/dataset.pickle\"\n",
    "    \n",
    "with open(dataset_path, \"rb\") as file:\n",
    "    dataset = pickle.load(file)\n",
    "    \n",
    "print(\"The following items were loaded:\")\n",
    "print(list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, we include 4500 training, 250 validation and 250 testing images. In total, there should be 18000 training, 1000 validation and 1000 testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data:\", dataset[\"train_data\"].shape)\n",
    "print(\"validation data:\", dataset[\"valid_data\"].shape)\n",
    "print(\"testing data:\", dataset[\"test_data\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual pixels are encoded as RGB values with integers in the range [0-255]. To help the classfier to converge, we **normalize** images so that they have zero mean and unit variance. \n",
    "\n",
    "**(Optional) Task**: Try skipping the normalization step or only subtracting means and see how it impacts the final performance (if the model trains at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(dataset[\"train_data\"], axis=0)\n",
    "std = np.std(dataset[\"train_data\"], axis=0)\n",
    "\n",
    "dataset[\"train_data\"] = (dataset[\"train_data\"] - mean) / std\n",
    "dataset[\"valid_data\"] = (dataset[\"valid_data\"] - mean) / std\n",
    "dataset[\"test_data\"] = (dataset[\"test_data\"] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we compute means and standard deviations over the training set. As expected, the training set has zero mean and unit variance after normalization. However, the means and variances of the validation and testing set slightly deviate. \n",
    "\n",
    "**Question**: Why do we use means and standard deviations computed over the training set to normalize the validation and testing sets?\n",
    "\n",
    "*Hint: generalization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset statistics\")\n",
    "print(\"training mean:\", np.round(np.mean(dataset[\"train_data\"]), 5), \", variance:\", \n",
    "                        np.round(np.var(dataset[\"train_data\"]), 5))\n",
    "print(\"validation mean:\", np.round(np.mean(dataset[\"valid_data\"]), 5), \", variance:\", \n",
    "                          np.round(np.var(dataset[\"valid_data\"]), 5))\n",
    "print(\"testing mean:\", np.round(np.mean(dataset[\"test_data\"]), 5), \", variance:\", \n",
    "                       np.round(np.var(dataset[\"test_data\"]), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle** the pictures to make sure that each mini-batch is an **unbiased sample** of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_labels = unison_shuffle(dataset[\"train_data\"], dataset[\"train_labels\"])\n",
    "valid_dataset, valid_labels = unison_shuffle(dataset[\"valid_data\"], dataset[\"valid_labels\"])\n",
    "test_dataset, test_labels = unison_shuffle(dataset[\"valid_data\"], dataset[\"test_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the labels of images are encoded as integers (i.e. 0 = cat, 1 = deer, etc.). However, our Neural Network will output a vector of probabilities. These vectors will be compared with the ground-truth classes to compute the loss. For convenience, we turn the labels into **one-hot vectors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_turn_to_one_hot(labels, num_labels=4):\n",
    "  if len(labels.shape) == 1:\n",
    "    one_hot = np.zeros((labels.shape[0], num_labels))\n",
    "    one_hot[np.arange(len(labels)), labels] = 1\n",
    "    return one_hot\n",
    "  else:\n",
    "    return labels\n",
    "\n",
    "train_labels = maybe_turn_to_one_hot(train_labels)\n",
    "valid_labels = maybe_turn_to_one_hot(valid_labels)\n",
    "test_labels = maybe_turn_to_one_hot(test_labels)\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', valid_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Convolutional Neural Networks ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (ConvNets) extend fully-connected networks with convolutional and pooling layers.\n",
    "\n",
    "![convolutional network](images/convolutional_network.png)\n",
    "\n",
    "[source of image](http://deeplearning.net/tutorial/lenet.html)\n",
    "\n",
    "A common ConvNets contains several sets of convolutional layers interleaved with pooling layers followed by one or two fully-connected layers. The convolutional and pooling layers take care of detecting descriptive features in the image, whereas the fully-connected layers carry out the final classification.\n",
    "\n",
    "\n",
    "The following section describes convolutional and pooling layers and explains how we can implement them in Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer consists of several filters that are convolved over the image. Each filter is a small Tensor of weights. The convolutional operation involves multiplying the set of weight with an image patch at each location, summing the values of the resulting Tensor and saving the final value into the output Tensor.\n",
    "\n",
    "![convolutional layer](images/convolutional_layer.jpeg)\n",
    "\n",
    "[source of image](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "Convolutional Layer can be added into the Tensorflow computational graph wth [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d).\n",
    "\n",
    "**Sample code**\n",
    "\n",
    "The following snippet creates a Convolutional Layer with 16 filters. Each filter is of size 3 x 3. A [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) activation function is applied after the layer, so that the model can learn non-linear mappings.\n",
    "\n",
    "```python\n",
    "conv1 = tf.layers.conv2d(input_data, 16, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer applies a pooling function (often maximum or average) over each location of each feature map of the input. It is usually used to downsample the input by keeping only the maximum value of each patch of the input, hence **max-pooling**.\n",
    "\n",
    "![pooling layer](images/pooling_layer.jpeg)\n",
    "\n",
    "[source of image](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "Add Max-Pooling Layer to the Tensorflow graph with [tf.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/layers/MaxPooling2D).\n",
    "\n",
    "** Sample code **\n",
    "\n",
    "The following snippet defines a Max-Pooling Layer that downsamples the input by a factor of 2.\n",
    "\n",
    "```python\n",
    "pool1 = tf.layers.max_pooling2d(conv1, (2, 2), (2, 2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (bonus points) ###\n",
    "\n",
    "Implement and train a Convolutional Neural Network on the animals dataset. There are many degrees of freedom when we create a ConvNet. We can choose the number of convolutions, where to put max-pooling layers, how many filters each convolutional layer has and so on. You can either come up with your own ConvNet or follow our recipe:\n",
    "\n",
    "* Conv1 : 16 3x3 filters with stride 1\n",
    "* Pool1 : downsample the input by a factor of 2\n",
    "* Conv2 : 32 3x3 filters with stride 1\n",
    "* Pool2 : downsample the input by a factor of 2\n",
    "* Flatten : vectorize the input so that we can pass it into a fully-connected layer\n",
    "* Dense1 : a fully-connected layer with 50 neurons\n",
    "* Logits : a fully-connected layer with 4 neurons: each outputs the score for one class in the dataset\n",
    "\n",
    "Useful links:\n",
    "* [lecture notes from Stanford University **(recommended)**](http://cs231n.github.io/convolutional-networks/)\n",
    "* [Tensorflow tutorial on Convolutional Networks](https://www.tensorflow.org/tutorials/layers)\n",
    "\n",
    "See the reference notebook for a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TF remembers everything you defined, this will keep the computation graph clean\n",
    "tf.reset_default_graph()   \n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "# placeholders for data, we will fill these using the feed dictionary during training\n",
    "input_data = tf.placeholder(tf.float32, (None, train_dataset.shape[1], train_dataset.shape[2], 3))\n",
    "input_labels = tf.placeholder(tf.int32, (None, train_labels.shape[1]))\n",
    "\n",
    "# define convolutional and pooling layers\n",
    "conv1 = tf.layers.conv2d(input_data, 16, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, (2, 2), (2, 2))\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, 32, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, (2, 2), (2, 2))\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "# define fully-connected (or dense) layers\n",
    "dense1 = tf.layers.dense(flattened, 50)\n",
    "logits = tf.layers.dense(dense1, 4)\n",
    "\n",
    "# define loss and training operation\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_labels, logits=logits))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# calcualte average accuracy over a batch of images\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(input_labels, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_steps = 1000\n",
    "mini_batch_size = 64\n",
    "log_frequency = 100\n",
    "\n",
    "# how many steps are in one epoch (epoch = one pass through the dataset)\n",
    "# e.g. number of training samples = 50, mini batch size = 10 => steps per epoch = 5\n",
    "steps_per_epoch = train_dataset.shape[0] // mini_batch_size\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "  # initialize all parameters of the neural network\n",
    "  session.run(tf.global_variables_initializer())\n",
    "\n",
    "  for step in range(num_steps):\n",
    "        \n",
    "    # step number relative to the current epoch (epoch = one pass through the dataset)\n",
    "    # e.g. number of training samples = 50, step = 60 => epoch step = 60 % 50 = 10\n",
    "    epoch_step = step % steps_per_epoch\n",
    "        \n",
    "    # start and end index for the current minibatch\n",
    "    # e.g. mini batch size = 64, start = 10, end = 74 => take all images from index 10 to 74\n",
    "    start = epoch_step * mini_batch_size\n",
    "    end = (epoch_step +  1) * mini_batch_size\n",
    "    \n",
    "    # if this is the first step in the current epoch, shuffle the training set\n",
    "    # we do this so that the model does not overfit on individual minibatches\n",
    "    if epoch_step == 0:\n",
    "        print(\"epoch\", step // steps_per_epoch)\n",
    "        train_dataset, train_labels = unison_shuffle(train_dataset, train_labels)\n",
    "    \n",
    "    # run one step of mini-batch gradient descent\n",
    "    batch_loss, batch_accuracy, _ = session.run([loss, accuracy, train_op], feed_dict={\n",
    "      input_data: train_dataset.take(range(start, end), axis=0, mode=\"wrap\"),\n",
    "      input_labels: train_labels.take(range(start, end), axis=0, mode=\"wrap\")\n",
    "    })\n",
    "    \n",
    "    # sometimes print the current loss\n",
    "    if step % log_frequency == 0:\n",
    "      print('step:', step, ', loss:', batch_loss, ', training accuracy:', batch_accuracy)\n",
    "    \n",
    "  print('Training finished after', num_steps, 'steps.')\n",
    "  \n",
    "  # evaluate the model on the validation set  \n",
    "  validation_accuracy = session.run(accuracy, feed_dict={\n",
    "    input_data: valid_dataset,\n",
    "    input_labels: valid_labels\n",
    "  })\n",
    "    \n",
    "  print('Validation accuracy', validation_accuracy, '.')\n",
    "\n",
    "# we do not save the model so the parameters are forgotten right after the training finishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Regularizing Convolutional Networks ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All neural networks are prone to overfitting if the training dataset is too small or the number of parameters too high.\n",
    "\n",
    "Dropout Layer is a simple but effective regularization technique. During training, certain percentage (dropout_prob) of inputs are set to 0 and the rest is scaled by 1 / dropout_prob, to keep the sum of the inputs unchanged. During testing, the layers does not do anything.\n",
    "\n",
    "Include dropout with [tf.layers.dropout](https://www.tensorflow.org/api_docs/python/tf/layers/dropout).\n",
    "\n",
    "\n",
    "\n",
    "### Task 2 (bonus points) ###\n",
    "\n",
    "Implement dropout for your ConvNet. See the reference notebook for a solution.\n",
    "\n",
    "** Sample code **\n",
    "\n",
    "The following snippet defines a Dropout Layer that drops 50% of the input values. The is_training placeholder decidedsif we are in training or testing mode and should be specified using the feed dictionary.\n",
    "\n",
    "```python\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "dropout = tf.layers.dropout(dense1, rate=0.5, training=is_training)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Task 3 ###\n",
    "\n",
    "So far, we only evaluated our models on the validation set. After you are confident with your choice of the ConvNet architecture and hyperparameters, you should evaluate the model on the testing set to get a more accurate estimate of the model's accuracy. The hyperparameters you chose might work particularly well for the images in the validation set but fail when classifying the test set.\n",
    "\n",
    "Evaluate your model on the testing set and compare the accuracy to the one computed over the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources   ##\n",
    "\n",
    "** Convolutional Networks **\n",
    "* [lecture notes from the Stanford University **(recommended)**](http://cs231n.github.io/convolutional-networks/)\n",
    "* [lecture video from the University of Oxford](https://www.youtube.com/watch?v=bEUX_56Lojc)\n",
    "* [Tensorflow tutorial](https://www.tensorflow.org/tutorials/layers)\n",
    "\n",
    "** Dropout **\n",
    "* [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/dropout)\n",
    "* [paper](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n",
    "\n",
    "** Advanced data loading features in Tensorflow **\n",
    "* [tutorial](https://www.tensorflow.org/programmers_guide/datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other dataset to try ##\n",
    "\n",
    "* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "* [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "* [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
